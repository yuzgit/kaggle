{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# レストラン収益予測"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データからレストランの年間売上高を予測する  \n",
    "提出CSVにはidと予測値を記述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセット内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Id        : レストランごとの振り分けID\n",
    "Open Date : レストランのオープン日  \n",
    "City      : レストランがある市  \n",
    "City Group: 市町村のタイプ  大都市、その他  \n",
    "Type      : レストランの種類(FC: フードコード IL: インライン DT: ドライブスルー MB: モバイル)  \n",
    "P1,P2-P37 : 座標データ  \n",
    "revenue   : 収益  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "# numpy, matplotlib, seaborn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 137 entries, 0 to 136\n",
      "Data columns (total 43 columns):\n",
      "Id            137 non-null int64\n",
      "Open Date     137 non-null object\n",
      "City          137 non-null object\n",
      "City Group    137 non-null object\n",
      "Type          137 non-null object\n",
      "P1            137 non-null int64\n",
      "P2            137 non-null float64\n",
      "P3            137 non-null float64\n",
      "P4            137 non-null float64\n",
      "P5            137 non-null int64\n",
      "P6            137 non-null int64\n",
      "P7            137 non-null int64\n",
      "P8            137 non-null int64\n",
      "P9            137 non-null int64\n",
      "P10           137 non-null int64\n",
      "P11           137 non-null int64\n",
      "P12           137 non-null int64\n",
      "P13           137 non-null float64\n",
      "P14           137 non-null int64\n",
      "P15           137 non-null int64\n",
      "P16           137 non-null int64\n",
      "P17           137 non-null int64\n",
      "P18           137 non-null int64\n",
      "P19           137 non-null int64\n",
      "P20           137 non-null int64\n",
      "P21           137 non-null int64\n",
      "P22           137 non-null int64\n",
      "P23           137 non-null int64\n",
      "P24           137 non-null int64\n",
      "P25           137 non-null int64\n",
      "P26           137 non-null float64\n",
      "P27           137 non-null float64\n",
      "P28           137 non-null float64\n",
      "P29           137 non-null float64\n",
      "P30           137 non-null int64\n",
      "P31           137 non-null int64\n",
      "P32           137 non-null int64\n",
      "P33           137 non-null int64\n",
      "P34           137 non-null int64\n",
      "P35           137 non-null int64\n",
      "P36           137 non-null int64\n",
      "P37           137 non-null int64\n",
      "revenue       137 non-null float64\n",
      "dtypes: float64(9), int64(30), object(4)\n",
      "memory usage: 46.1+ KB\n",
      "---------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 42 columns):\n",
      "Id            100000 non-null int64\n",
      "Open Date     100000 non-null object\n",
      "City          100000 non-null object\n",
      "City Group    100000 non-null object\n",
      "Type          100000 non-null object\n",
      "P1            100000 non-null int64\n",
      "P2            100000 non-null float64\n",
      "P3            100000 non-null float64\n",
      "P4            100000 non-null float64\n",
      "P5            100000 non-null int64\n",
      "P6            100000 non-null int64\n",
      "P7            100000 non-null int64\n",
      "P8            100000 non-null int64\n",
      "P9            100000 non-null int64\n",
      "P10           100000 non-null int64\n",
      "P11           100000 non-null int64\n",
      "P12           100000 non-null int64\n",
      "P13           100000 non-null float64\n",
      "P14           100000 non-null int64\n",
      "P15           100000 non-null int64\n",
      "P16           100000 non-null int64\n",
      "P17           100000 non-null int64\n",
      "P18           100000 non-null int64\n",
      "P19           100000 non-null int64\n",
      "P20           100000 non-null int64\n",
      "P21           100000 non-null int64\n",
      "P22           100000 non-null int64\n",
      "P23           100000 non-null int64\n",
      "P24           100000 non-null int64\n",
      "P25           100000 non-null int64\n",
      "P26           100000 non-null float64\n",
      "P27           100000 non-null float64\n",
      "P28           100000 non-null float64\n",
      "P29           100000 non-null float64\n",
      "P30           100000 non-null int64\n",
      "P31           100000 non-null int64\n",
      "P32           100000 non-null int64\n",
      "P33           100000 non-null int64\n",
      "P34           100000 non-null int64\n",
      "P35           100000 non-null int64\n",
      "P36           100000 non-null int64\n",
      "P37           100000 non-null int64\n",
      "dtypes: float64(8), int64(30), object(4)\n",
      "memory usage: 32.0+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('datasets/train.csv')\n",
    "test_df  = pd.read_csv('datasets/test.csv')\n",
    "\n",
    "# 内容チェック\n",
    "train_df.info()\n",
    "print('---------------------------------------')\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 各カラムの詳細な調査"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['IL', 'FC', 'DT'], dtype=object)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Typeカラム\n",
    "# unique(): ユニーク(一意)な値のリストをndarrayで返す\n",
    "# MBは存在しない模様\n",
    "train_df['Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Big Cities', 'Other'], dtype=object)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# City Groupカラム\n",
    "# 大都市、その他のみ\n",
    "train_df['City Group'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['İstanbul', 'Ankara', 'Diyarbakır', 'Tokat', 'Gaziantep',\n",
       "       'Afyonkarahisar', 'Edirne', 'Kocaeli', 'Bursa', 'İzmir', 'Sakarya',\n",
       "       'Elazığ', 'Kayseri', 'Eskişehir', 'Şanlıurfa', 'Samsun', 'Adana',\n",
       "       'Antalya', 'Kastamonu', 'Uşak', 'Muğla', 'Kırklareli', 'Konya',\n",
       "       'Karabük', 'Tekirdağ', 'Denizli', 'Balıkesir', 'Aydın', 'Amasya',\n",
       "       'Kütahya', 'Bolu', 'Trabzon', 'Isparta', 'Osmaniye'], dtype=object)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cityカラム\n",
    "train_df['City'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各特徴が文字列のままだと学習できないのでこれらを0,1のフラグで分類できるようにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id              int64\n",
      "P1              int64\n",
      "P2            float64\n",
      "P3            float64\n",
      "P4            float64\n",
      "P5              int64\n",
      "P6              int64\n",
      "P7              int64\n",
      "P8              int64\n",
      "P9              int64\n",
      "P10             int64\n",
      "P11             int64\n",
      "P12             int64\n",
      "P13           float64\n",
      "P14             int64\n",
      "P15             int64\n",
      "P16             int64\n",
      "P17             int64\n",
      "P18             int64\n",
      "P19             int64\n",
      "P20             int64\n",
      "P21             int64\n",
      "P22             int64\n",
      "P23             int64\n",
      "P24             int64\n",
      "P25             int64\n",
      "P26           float64\n",
      "P27           float64\n",
      "P28           float64\n",
      "P29           float64\n",
      "P30             int64\n",
      "P31             int64\n",
      "P32             int64\n",
      "P33             int64\n",
      "P34             int64\n",
      "P35             int64\n",
      "P36             int64\n",
      "P37             int64\n",
      "revenue       float64\n",
      "Type_IL         int64\n",
      "Type_FC         int64\n",
      "Type_DT         int64\n",
      "Big_Cities      int64\n",
      "Days_Open       int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Type\n",
    "# 持っている特徴の'IL','FC','DT'をそれぞれ個別のカラムにする\n",
    "# np.where: 第一引数が成立するなら1をそうでなければ０を返す\n",
    "# つまりILならILが存在するレコードなら1が返される\n",
    "train_df['Type_IL'] = np.where(train_df['Type'] == 'IL', 1, 0)\n",
    "train_df['Type_FC'] = np.where(train_df['Type'] == 'FC', 1, 0)\n",
    "train_df['Type_DT'] = np.where(train_df['Type'] == 'DT', 1, 0)\n",
    "\n",
    "test_df['Type_IL'] = np.where(test_df['Type'] == 'IL', 1, 0)\n",
    "test_df['Type_FC'] = np.where(test_df['Type'] == 'FC', 1, 0)\n",
    "test_df['Type_DT'] = np.where(test_df['Type'] == 'DT', 1, 0)\n",
    "\n",
    "# City Group\n",
    "train_df['Big_Cities'] = np.where(train_df['City Group'] == 'Big Cities', 1, 0)\n",
    "train_df['Days_Open'] = (pd.to_datetime('2015-03-23') - pd.to_datetime(train_df['Open Date'])).dt.days\n",
    "\n",
    "test_df['Big_Cities'] = np.where(test_df['City Group'] == 'Big Cities', 1, 0)\n",
    "test_df['Days_Open'] = (pd.to_datetime('2015-03-23') - pd.to_datetime(test_df['Open Date'])).dt.days\n",
    "\n",
    "# 不要なカラムはDrop\n",
    "train_df = train_df.drop('Type', axis=1)\n",
    "train_df = train_df.drop('City Group', axis=1)\n",
    "train_df = train_df.drop('City', axis=1)\n",
    "train_df = train_df.drop('Open Date', axis=1)\n",
    "\n",
    "test_df = test_df.drop('Type', axis=1)\n",
    "test_df = test_df.drop('City Group', axis=1)\n",
    "test_df = test_df.drop('City', axis=1)\n",
    "test_df = test_df.drop('Open Date', axis=1)\n",
    "\n",
    "# objectがなくなったか確認\n",
    "print(train_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X,Yの分断"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       5653753.0\n",
      "1       6923131.0\n",
      "2       2055379.0\n",
      "3       2675511.0\n",
      "4       4316715.0\n",
      "5       5017319.0\n",
      "6       5166635.0\n",
      "7       4491607.0\n",
      "8       4952497.0\n",
      "9       5444227.0\n",
      "10      3745135.0\n",
      "11      5161370.0\n",
      "12      1734634.0\n",
      "13      4807746.0\n",
      "14      1999097.0\n",
      "15      3218918.0\n",
      "16     19696939.0\n",
      "17      8213524.0\n",
      "18      5337526.0\n",
      "19      2021934.0\n",
      "20      5525735.0\n",
      "21      1149870.0\n",
      "22      3956086.0\n",
      "23      2999068.0\n",
      "24      8904084.0\n",
      "25      3778621.0\n",
      "26      2267425.0\n",
      "27      5435276.0\n",
      "28      4705945.0\n",
      "29      3447890.0\n",
      "          ...    \n",
      "107     3248660.0\n",
      "108     3570392.0\n",
      "109     4219263.0\n",
      "110     2954086.0\n",
      "111     2993069.0\n",
      "112     3784230.0\n",
      "113     2097022.0\n",
      "114     4155435.0\n",
      "115     4882985.0\n",
      "116     8894598.0\n",
      "117     2018785.0\n",
      "118     1847826.0\n",
      "119     3780019.0\n",
      "120     4067566.0\n",
      "121     3445076.0\n",
      "122     4286645.0\n",
      "123     4263629.0\n",
      "124     3810007.0\n",
      "125     4780607.0\n",
      "126     4015749.0\n",
      "127     7592272.0\n",
      "128     2383840.0\n",
      "129     3939804.0\n",
      "130     3376145.0\n",
      "131     3199619.0\n",
      "132     5787594.0\n",
      "133     9262754.0\n",
      "134     2544857.0\n",
      "135     7217634.0\n",
      "136     6363241.0\n",
      "Name: revenue, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "\n",
    "X = train_df.drop(['Id', 'revenue'], axis=1)\n",
    "Y = train_df.revenue\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ランダムフォレスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86839789616260776"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=150)\n",
    "model.fit(X, Y)\n",
    "model.score(X,Y)\n",
    "\n",
    "test_predicted = pd.DataFrame()\n",
    "test_predicted['Id'] = test_df.Id\n",
    "test_predicted['Prediction'] = model.predict(test_df.drop('Id', axis=1))\n",
    "test_predicted.to_csv('submissioncsv/submission-logreg.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-4.2.0]",
   "language": "python",
   "name": "conda-env-anaconda3-4.2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
